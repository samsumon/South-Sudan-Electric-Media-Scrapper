{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b4ba34-dd42-44f8-aa8d-8851b9c9cc5e",
   "metadata": {},
   "source": [
    "<h2> Import packages </h2> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07320d88-9c9a-4cc5-9961-766625392e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2b1d4-9ae8-4363-9f22-9b82ce34a5be",
   "metadata": {},
   "source": [
    "# Instructions: \n",
    "Find the line of code that states the while loop and set x less than\n",
    "the number of pages you would like to crawl.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd3dc4f-9c67-4d0e-9958-b402241dbf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You just crawled the website:https://allafrica.com/southsudan/?page=1!\n",
      "\n",
      "\n",
      "You just crawled the website:https://allafrica.com/southsudan/?page=2!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "headlines = []\n",
    "links = []\n",
    "sources = []\n",
    "location = []\n",
    "url = 'https://allafrica.com/southsudan/?page=' + str(x)\n",
    "while x < 3:\n",
    "    source = requests.get(url)\n",
    "    soup = BeautifulSoup(source.content, 'html.parser')\n",
    "    print('You just crawled the website:' + url + \"!\")\n",
    "    print('\\n')\n",
    "    for head in soup.find_all('li'):\n",
    "        head_line = head.find(\"span\", {'class': 'headline'})\n",
    "        if head_line is None:\n",
    "            print(\"\", end=\"\")\n",
    "        else:\n",
    "            headlines.append(head_line.get_text())\n",
    "    ul = soup.find('ul', {\"class\": 'stories'})\n",
    "    for a in ul.find_all('a'):\n",
    "        links.append('https://allafrica.com/' + a['href'])\n",
    "    for p in ul.find_all('p', {'class': 'source'}):\n",
    "        sources.append(p.get_text())\n",
    "    for area in soup.find_all('p', {'class': 'title'}):\n",
    "        title = area.find('span', {'class': 'location'})\n",
    "        location.append(title.get_text())\n",
    "    x = x + 1\n",
    "    url = 'https://allafrica.com/southsudan/?page=' + str(x)\n",
    "with open(\"All_Africa.csv\", \"w\", newline=\"\") as t:\n",
    "    csv_writer = csv.writer(t, delimiter=',')\n",
    "    csv_writer.writerow(['Location', 'Source', 'Links', 'Headline'])\n",
    "    for i in range(0, len(location)):\n",
    "        csv_writer.writerows([[location[i], sources[i], links[i], headlines[i]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2be3a2-f061-40d4-aac6-2fa1581b6bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
